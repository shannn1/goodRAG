{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817f3b7c-5a8a-44bf-8fed-269b8404ba4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db64640a73d4282b1b93f2e3dc7716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/397 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d37fd035fcd4ad7bc4649d59de03532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29311bee17bd4366871531ab92b667d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4212 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Shannnh/baseline-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbe13d6-251c-440c-91a4-7c9c75eafa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question', 'answers', 'predicted_answer'],\n",
      "        num_rows: 4212\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbef538f-6f79-4f6b-8a83-1b8e52b7ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3776f2-6497-4f92-bdcc-e8b5ef8251c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.3934\n"
     ]
    }
   ],
   "source": [
    "def calculate_f1(predicted, ground_truth):\n",
    "    pred_tokens = predicted.split()\n",
    "    gt_tokens = ground_truth.split()\n",
    "    common = set(pred_tokens) & set(gt_tokens)\n",
    "    if len(common) == 0:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gt_tokens)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "f1_scores = [calculate_f1(pred, gt) for pred, gt in zip(data[\"predicted_answer\"], data[\"answers\"])]\n",
    "average_f1 = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"Average F1 Score: {average_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f1b87f-dde2-42da-b63d-208f54507fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Score: 0.1968\n"
     ]
    }
   ],
   "source": [
    "def calculate_exact_match(predicted, ground_truth):\n",
    "    return int(predicted.strip() == ground_truth.strip())\n",
    "\n",
    "em_scores = [calculate_exact_match(pred, gt) for pred, gt in zip(data[\"predicted_answer\"], data[\"answers\"])]\n",
    "average_em = sum(em_scores) / len(em_scores)\n",
    "print(f\"Exact Match Score: {average_em:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a104f9-7588-40b0-a09b-64b7f4a9f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def calculate_bleu(predicted, ground_truth):\n",
    "    reference = [ground_truth.split()]  # 参考答案的 n-grams\n",
    "    hypothesis = predicted.split()  # 预测答案的 n-grams\n",
    "    return sentence_bleu(reference, hypothesis)\n",
    "\n",
    "bleu_scores = [calculate_bleu(pred, gt) for pred, gt in zip(data[\"predicted_answer\"], data[\"answers\"])]\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "print(f\"Average BLEU Score: {average_bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140fa24-fe72-4d9a-ae01-4f14045f6da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
