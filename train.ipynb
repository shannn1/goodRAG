{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip uninstall -y faiss faiss-cpu faiss-gpu\n",
        "!pip install faiss-cpu\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDkpvk7iNbCv",
        "outputId": "a21f7c85-daa1-4d58-d55a-74c82cdb0fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "\u001b[33mWARNING: Skipping faiss as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: faiss-cpu 1.9.0.post1\n",
            "Uninstalling faiss-cpu-1.9.0.post1:\n",
            "  Successfully uninstalled faiss-cpu-1.9.0.post1\n",
            "\u001b[33mWARNING: Skipping faiss-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Using cached faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.9.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import faiss\n",
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "from transformers import (\n",
        "    AutoModel,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    RagTokenizer,\n",
        "    RagRetriever,\n",
        "    RagSequenceForGeneration,\n",
        "    RagConfig,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    AdamW,\n",
        ")"
      ],
      "metadata": {
        "id": "6wcreuzUaU6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_base = load_dataset(\"Shannnh/knowledge_base_genai\")\n",
        "knowledge_base = knowledge_base['train']\n",
        "knowledge_base = knowledge_base.rename_column(\"document\", \"text\")\n",
        "output_path = \"./knowledge_base\"  # 保存路径\n",
        "knowledge_base.save_to_disk(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "372986372b974c62b8a8f73c1859d6e2",
            "6f4ce231235748bab9cb4d28f620a761",
            "fbafddb7e6954787bf57d30e15e5705e",
            "df5aa8a34635462c814dddf7b6f64294",
            "093136e6ebe74c39bf3ed3f19541ca67",
            "31eede22968c4dc680e80178c2c08d37",
            "edce283df7654c6eaa4378f97e701c05",
            "b7255959c701467a9b38d08c92bfb816",
            "a51e250277c64c81a7b6dbff65408344",
            "79c49ba9f87444958b70dff8e5f13564",
            "3f16267e011243f3b15f5b29e9bf7e5f"
          ]
        },
        "id": "dAO0cP7madTF",
        "outputId": "e5f9080d-41b6-4bc3-fa03-1677db3b485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/8 shards):   0%|          | 0/78529 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "372986372b974c62b8a8f73c1859d6e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成model\n",
        "\n",
        "retriever = RagRetriever.from_pretrained(\n",
        "    \"facebook/rag-sequence-nq\",\n",
        "    index_name=\"custom\",\n",
        "    passages_path=\"./knowledge_base\",\n",
        "    index_path=\"./faiss_index\",\n",
        "    repo_type='knowledge_base'\n",
        ")\n",
        "\n",
        "model_name = \"facebook/rag-sequence-nq\"\n",
        "model = RagSequenceForGeneration.from_pretrained(model_name, retriever=retriever)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZgGcfmgbCft",
        "outputId": "273aca7c-20b5-4f29-e86e-84300cbc8e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n",
            "Some weights of the model checkpoint at facebook/rag-sequence-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"rag_finetuning\", name=\"rag_finetune_run\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
        "datasets = load_dataset(\"lighteval/natural_questions_clean\")\n",
        "\n",
        "# Split train and validation\n",
        "full_train_data = datasets['train']\n",
        "train_val_split = full_train_data.train_test_split(test_size=0.1, seed=42)\n",
        "train_data = train_val_split['train']\n",
        "validation_data = train_val_split['test']\n",
        "\n",
        "# Rename columns\n",
        "train_data = train_data.rename_column(\"short_answers\", \"answer\")\n",
        "validation_data = validation_data.rename_column(\"short_answers\", \"answer\")\n",
        "\n",
        "device = 'cpu'\n",
        "\n",
        "# Freeze question encoder parameters\n",
        "for param in model.rag.question_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "def preprocess_function(batch):\n",
        "    questions = [q if isinstance(q, str) else \"\" for q in batch['question']]\n",
        "    answers = [a if isinstance(a, str) else \"\" for a in batch['answer']]\n",
        "    inputs = tokenizer(questions, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    targets = tokenizer(answers, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].tolist(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].tolist(),\n",
        "        \"labels\": targets[\"input_ids\"].tolist(),\n",
        "    }\n",
        "\n",
        "train_dataset = train_data.map(preprocess_function, batched=True)\n",
        "validation_dataset = validation_data.map(preprocess_function, batched=True)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor([item[\"input_ids\"] for item in batch]),\n",
        "        \"attention_mask\": torch.tensor([item[\"attention_mask\"] for item in batch]),\n",
        "        \"labels\": torch.tensor([item[\"labels\"] for item in batch]),\n",
        "    }\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=512, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "epochs = 1\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training loop\n",
        "    train_loss_total = 0.0\n",
        "    train_steps = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_total += loss.item()\n",
        "        train_steps += 1\n",
        "\n",
        "        # Log step loss to wandb\n",
        "        wandb.log({\"train_loss_step\": loss.item()})\n",
        "\n",
        "    # Compute average training loss for the epoch\n",
        "    avg_train_loss = train_loss_total / train_steps if train_steps > 0 else 0.0\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_steps = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "            val_steps += 1\n",
        "\n",
        "    avg_val_loss = val_loss / val_steps if val_steps > 0 else 0.0\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "    # Log epoch losses to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss_epoch\": avg_train_loss,\n",
        "        \"val_loss_epoch\": avg_val_loss\n",
        "    })\n",
        "\n",
        "    model.train()\n",
        "\n",
        "model.save_pretrained(\"finetuned_rag\")\n",
        "tokenizer.save_pretrained(\"finetuned_rag\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "n4upaaP0Seng",
        "outputId": "0c696560-528b-4c7c-9811-16c303ba29b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlzheng2\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_231143-x31190tl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lzheng2/rag_finetuning/runs/x31190tl' target=\"_blank\">rag_finetune_run</a></strong> to <a href='https://wandb.ai/lzheng2/rag_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lzheng2/rag_finetuning' target=\"_blank\">https://wandb.ai/lzheng2/rag_finetuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lzheng2/rag_finetuning/runs/x31190tl' target=\"_blank\">https://wandb.ai/lzheng2/rag_finetuning/runs/x31190tl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "model = RagSequenceForGeneration.from_pretrained(\"finetuned_rag\")\n",
        "# tokenizer = RagTokenizer.from_pretrained(\"finetuned_rag\")\n",
        "\n",
        "# Load the original validation dataset\n",
        "datasets = load_dataset(\"lighteval/natural_questions_clean\")\n",
        "val_data = datasets['validation']\n",
        "\n",
        "# Rename column for consistency\n",
        "val_data = val_data.rename_column(\"short_answers\", \"answer\")\n",
        "\n",
        "# Preprocessing function for inference\n",
        "def preprocess_function(batch):\n",
        "    questions = [q if isinstance(q, str) else \"\" for q in batch['question']]\n",
        "    # During inference, we only need input_ids and attention_mask for questions\n",
        "    inputs = tokenizer(questions, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"input_ids\": inputs[\"input_ids\"].tolist(),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].tolist(),\n",
        "    }\n",
        "\n",
        "# Apply the preprocessing to the validation data\n",
        "val_processed = val_data.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define collate function to prepare batches\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor([item[\"input_ids\"] for item in batch]),\n",
        "        \"attention_mask\": torch.tensor([item[\"attention_mask\"] for item in batch]),\n",
        "    }\n",
        "\n",
        "val_dataloader = DataLoader(val_processed, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "model.eval()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "predictions = []\n",
        "ids = []\n",
        "questions = []\n",
        "original_answers = []\n",
        "\n",
        "# Inference loop\n",
        "for i, val_batch in enumerate(val_dataloader):\n",
        "    input_ids = val_batch[\"input_ids\"].to(device)\n",
        "    attention_mask = val_batch[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Generate predicted answers\n",
        "    # Adjust max_length as needed\n",
        "    output_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=50)\n",
        "    predicted_answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Retrieve the original data by index i\n",
        "    original_item = val_data[i]\n",
        "\n",
        "    ids.append(original_item[\"id\"])\n",
        "    questions.append(original_item[\"question\"])\n",
        "    original_answers.append(original_item[\"answer\"])\n",
        "    predictions.append(predicted_answer)\n",
        "\n",
        "# Create a new dataset with the results\n",
        "results = Dataset.from_dict({\n",
        "    \"id\": ids,\n",
        "    \"question\": questions,\n",
        "    \"original_answer\": original_answers,\n",
        "    \"predicted_answer\": predictions\n",
        "})\n",
        "\n",
        "results.push_to_hub(\"username/my_finetuned_rag_predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "69d246b47e1e4bd69fecd9d0d1e961d3",
            "cab9f1c13c76435a8a11fc10e7a5bd3f",
            "8f03936950334cf384e91854c51e08d9",
            "6fdd1f77c6a64365a7c8f0e20f0e9832",
            "fa1e3f2f626a4857b1683b7bfd68aeb2",
            "69a1b570495c4e53b1cb44f08a98d7f3",
            "a001bc2ee6f14e448ac104f0b138b5be",
            "d8ead3df64f74d9db3c8929182b25e55",
            "79701ff27a5e49cdb61a83c295f9832b",
            "5d8d66aaa7584e8f89084f120c20e180",
            "138b563462224d47b29360bd8e34d78d"
          ]
        },
        "id": "oH3z2lQoRwxN",
        "outputId": "9fcf2645-1c23-4214-a74d-b6bdc1f250c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4289 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69d246b47e1e4bd69fecd9d0d1e961d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4c3b43f12d5b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Generate predicted answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Adjust max_length as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mpredicted_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/rag/modeling_rag.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, attention_mask, context_input_ids, context_attention_mask, doc_scores, do_deduplication, num_return_sequences, num_beams, n_docs, **model_kwargs)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;31m# first, generate beams from documents:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0mgenerator_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_input_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_docs\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_docs\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (n_docs, max_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             output_sequences = self.generator.generate(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1(predicted, ground_truth):\n",
        "    pred_tokens = predicted.split()\n",
        "    gt_tokens = ground_truth.split()\n",
        "    common = set(pred_tokens) & set(gt_tokens)\n",
        "    if len(common) == 0:\n",
        "        return 0.0\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(gt_tokens)\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "f1_scores = [calculate_f1(pred, gt) for pred, gt in zip(results[\"predicted_answer\"], results[\"original_answer\"])]\n",
        "average_f1 = sum(f1_scores) / len(f1_scores)\n",
        "print(f\"Average F1 Score: {average_f1:.4f}\")"
      ],
      "metadata": {
        "id": "vaFrLQ5rVS_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_exact_match(predicted, ground_truth):\n",
        "    return int(predicted.strip() == ground_truth.strip())\n",
        "\n",
        "em_scores = [calculate_exact_match(pred, gt) for pred, gt in zip(results[\"predicted_answer\"], results[\"original_answer\"])]\n",
        "average_em = sum(em_scores) / len(em_scores)\n",
        "print(f\"Exact Match Score: {average_em:.4f}\")"
      ],
      "metadata": {
        "id": "LmnGHL6cVgwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def calculate_q_bleu(predicted, ground_truth, question):\n",
        "    # Tokenize inputs\n",
        "    ref_tokens = ground_truth.split()\n",
        "    hyp_tokens = predicted.split()\n",
        "    question_tokens = question.split()\n",
        "\n",
        "    reference = [ref_tokens]\n",
        "    hypothesis = hyp_tokens\n",
        "    bleu_score = sentence_bleu(reference, hypothesis)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    important_ref_tokens = [token for token in ref_tokens if token.lower() not in stop_words]\n",
        "    important_hyp_tokens = [token for token in hyp_tokens if token.lower() not in stop_words]\n",
        "\n",
        "    key_match = len(set(important_ref_tokens) & set(important_hyp_tokens)) / max(len(set(important_ref_tokens)), 1)\n",
        "\n",
        "    question_match = len(set(question_tokens) & set(hyp_tokens)) / max(len(set(question_tokens)), 1)\n",
        "\n",
        "    q_bleu = 0.7 * bleu_score + 0.2 * key_match + 0.1 * question_match\n",
        "\n",
        "    return q_bleu\n",
        "\n",
        "q_bleu_scores = [\n",
        "    calculate_q_bleu(pred, gt, q)\n",
        "    for pred, gt, q in zip(results[\"predicted_answer\"], results[\"original_answer\"], results[\"question\"])\n",
        "]\n",
        "average_q_bleu = sum(q_bleu_scores) / len(q_bleu_scores)\n",
        "print(f\"Average Q-BLEU Score: {average_q_bleu:.4f}\")"
      ],
      "metadata": {
        "id": "aRubiTWCVnng"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "372986372b974c62b8a8f73c1859d6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f4ce231235748bab9cb4d28f620a761",
              "IPY_MODEL_fbafddb7e6954787bf57d30e15e5705e",
              "IPY_MODEL_df5aa8a34635462c814dddf7b6f64294"
            ],
            "layout": "IPY_MODEL_093136e6ebe74c39bf3ed3f19541ca67"
          }
        },
        "6f4ce231235748bab9cb4d28f620a761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31eede22968c4dc680e80178c2c08d37",
            "placeholder": "​",
            "style": "IPY_MODEL_edce283df7654c6eaa4378f97e701c05",
            "value": "Saving the dataset (8/8 shards): 100%"
          }
        },
        "fbafddb7e6954787bf57d30e15e5705e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7255959c701467a9b38d08c92bfb816",
            "max": 78529,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a51e250277c64c81a7b6dbff65408344",
            "value": 78529
          }
        },
        "df5aa8a34635462c814dddf7b6f64294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79c49ba9f87444958b70dff8e5f13564",
            "placeholder": "​",
            "style": "IPY_MODEL_3f16267e011243f3b15f5b29e9bf7e5f",
            "value": " 78529/78529 [00:26&lt;00:00, 4574.86 examples/s]"
          }
        },
        "093136e6ebe74c39bf3ed3f19541ca67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31eede22968c4dc680e80178c2c08d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edce283df7654c6eaa4378f97e701c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7255959c701467a9b38d08c92bfb816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51e250277c64c81a7b6dbff65408344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79c49ba9f87444958b70dff8e5f13564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f16267e011243f3b15f5b29e9bf7e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69d246b47e1e4bd69fecd9d0d1e961d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab9f1c13c76435a8a11fc10e7a5bd3f",
              "IPY_MODEL_8f03936950334cf384e91854c51e08d9",
              "IPY_MODEL_6fdd1f77c6a64365a7c8f0e20f0e9832"
            ],
            "layout": "IPY_MODEL_fa1e3f2f626a4857b1683b7bfd68aeb2"
          }
        },
        "cab9f1c13c76435a8a11fc10e7a5bd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a1b570495c4e53b1cb44f08a98d7f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a001bc2ee6f14e448ac104f0b138b5be",
            "value": "Map: 100%"
          }
        },
        "8f03936950334cf384e91854c51e08d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ead3df64f74d9db3c8929182b25e55",
            "max": 4289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79701ff27a5e49cdb61a83c295f9832b",
            "value": 4289
          }
        },
        "6fdd1f77c6a64365a7c8f0e20f0e9832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8d66aaa7584e8f89084f120c20e180",
            "placeholder": "​",
            "style": "IPY_MODEL_138b563462224d47b29360bd8e34d78d",
            "value": " 4289/4289 [00:03&lt;00:00, 1624.57 examples/s]"
          }
        },
        "fa1e3f2f626a4857b1683b7bfd68aeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a1b570495c4e53b1cb44f08a98d7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a001bc2ee6f14e448ac104f0b138b5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ead3df64f74d9db3c8929182b25e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79701ff27a5e49cdb61a83c295f9832b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d8d66aaa7584e8f89084f120c20e180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138b563462224d47b29360bd8e34d78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}